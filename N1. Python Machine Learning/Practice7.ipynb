{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "**1. 다음 그래프 중 가장 강한 양의 상관관계를 가진 그래프를 고르시오.**\n",
    "![](../Image/Practice7_1.png)\n",
    "\n",
    "> 답 : 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**2 다음 수식에 관한 설명 중 틀린 것을 고르시오.**\n",
    "$$J(w_0, w_1)=\\frac{1}{2m}\\sum^{m}_{i=1}(h_0(x^{(i)}-y{(i)})^2$$\n",
    "\n",
    "1. 위 수식에서 다루는 피쳐의 개수는 하나이다.\n",
    "2. $y^{(i)}$는 $i$번째 실제값 $y$를 의미한다.\n",
    "3. 가설함수의 $h$의 $\\theta$는 두 개의 가중치 매개변수를 가지고 있다.\n",
    "4. 수식 앞에 $2m$ 중 2는 중요한 정규화텀(normalization term)으로, 없을 경우 연산되지 않는다.\n",
    "\n",
    "> 답 : 4"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "__3 경사하강법에 대한 설명으로 옳지 않은 것을 고르시오.__\n",
    "\n",
    "1. 경사하강법은 최소자승법과 비교할 때 큰 데이터에서도 정확한 답을 구할 수 있다.\n",
    "2. 경사하강법의 하이퍼 매개변수는 크게 데이터의 개수와 피쳐의 개수가 있다.\n",
    "3. 반복은 어느 시점이 지나면 더 이상 손실(loss) 값이 감소하지 않는다.\n",
    "4. 학습률(learning rate)이 너무 클 경우 손실(loss)이 발산하여 수렴하지 못하는 현상이 생길 수도 있다.\n",
    "\n",
    "> 답 : 4"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "__4. 다음 수식을 사용하여 최소자승법으로 선형회귀 문제를 풀려고 한다. 다음 설명 중 틀린 것을 고르시오.__\n",
    "$$\\hat{w}=(X^TX)^{-1}X^Ty$$\n",
    "\n",
    "1. $X^TX$가 존재할 때 문제의 해를 구할 수 있다.\n",
    "2. 데이터의 개수가 피쳐의 개수보다 많아야 한다.\n",
    "3. 경사하강법 알고리즘에 비해 데이터가 늘어나면 느려진다.\n",
    "4. 반복(iteration) 없이 바로 연산할 수 있으며, 하이퍼 매개변수가 존재하지 않는다.\n",
    "\n",
    "> 답 : 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "__5. 회귀식의 성능을 측정하기 위해 사용되는 MAE, RMSE, 결정계수(R-squared)에 대한 설명으로 적절한 것을 고르시오.__\n",
    "\n",
    "\n",
    "1. RMSE는 예측값과 실제값의 차이에 대한 제곱을 모두 합한 후 제곱근 연산을 한 값으로, 사이킷런의 root_mean_scored_error 함수를 사용할 수 있다.\n",
    "2. MAE는 에측값과 실제값 간의 차이에 대한 합을 데이터 개수n 으로 나눈 값으로 계산된다.\n",
    "3. 결정계수(R-squared)는 두 값의 상관도를 지표화하여 -1에서 1까지의 값을 출력한다.\n",
    "4. 이상치가 많을 경우에는 RMSE가 MAE보다 왜곡 정도를 좀 더 효과적으로 표현한다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "__6. 다음과 같은 데이터가 있는데, ‘Midterm Exam’ 점수와 ‘(Midterm Exam)$^2$’ 점수를 피쳐로 하여, ‘Final Exam’ 점수를 예측한다고 하자.__\n",
    "__다음 데이터를 각각 Z-score 표준화로 피쳐 스케일링(feature scaling)을 한다고 했을 때, 3번째 데이터에 대한 변환 값이 얼마인지 고르시오.__\n",
    "\n",
    "1. [1, 1]\n",
    "2. [1.21, 1.24]\n",
    "3. [5, 4]\n",
    "4. [0.74, 0.71]\n",
    "\n",
    "> 답 : 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "__8. 다음 코드는 선형회귀의 여러 구성 요소 중 하나를 구현한 코드이다. 이 코드에서 theta가 의미하는 수식은 무엇인지 고르시오.__"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def my_code_number(x, y, theta, alpha, m, numIterations):\n",
    "    x_trans = x.transpose()\n",
    "    theta_list = []\n",
    "    cost_list = []\n",
    "    for i in range(0, numIterations):\n",
    "        hypothesis = np.dot(x, theta)\n",
    "        loss = hypothesis - y\n",
    "        cost = np.sum(loss ** 2) / (2 * m)\n",
    "        gradient = np.dot(x_trans, loss) / m\n",
    "\n",
    "        theta = theta - alpha * gradient\n",
    "        if i % 250 == 0:\n",
    "            theta_list.append(theta)\n",
    "            cost_list.append(cost)\n",
    "        return theta, np.array(theta_list), cost_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. $J(w_0, w_1)=\\frac{1}{2m}\\sum^{m}_{i=1}(w_1x^{(1)}+w_0-y^{(i)})^2$\n",
    "2. loop until convergence { $do\\theta_j;=\\theta_j-a\\frac{\\partial}{\\partial\\partial_j}J(\\theta_0\\theta_1)$ }\n",
    "3. $\\hat{w}=(X^TX)^{-1}X^Ty$\n",
    "4. $\\frac{\\partial J}{\\partial w_1}=\\frac{1}{m}\\sum^{m}_{i=1}(w_1x{(i)}+w_0-y^{(i)})x^{(i)}$\n",
    "\n",
    "> 답 : 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "__9. 경사하강법에서 학습률(learning rate)과 반복(iteration) 횟수가 중요한 하이퍼 매개변수인 이유로 맞는 설명을 고르시오.__\n",
    "\n",
    "1. 학습률이 크면 클수록 학습의 속도가 빨라진다.\n",
    "2. 반복이 많을수록 최종 성능이 높아진다.\n",
    "3. 학습률이 너무 작을 경우 학습 시간이 늦어지고, 반복이 충분하지 않을 경우 손실(loss)이 수렴되지 않는다.\n",
    "4. 학습률이 작으면 세부적인 학습이 가능하며, 학습의 정확도를 위해 작게 하는 것이 좋다.\n",
    "\n",
    "> 답 : 3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "__10. 선형회귀에서 피쳐 스케일링(feature scaling)을 사용하는 이유로 적절한 것을 고르시오.__\n",
    "\n",
    "1. 피쳐들의 값을 정규화함으로써 경사하강법 적용 시 학습 시간이 단축된다.\n",
    "2. 최소자승법 적용 시 연산 속도가 단축된다.\n",
    "3. 피쳐 값의 이상치가 많을수록 최솟값-최댓값(Min-Max) 스케일링 기법이 유효하다.\n",
    "4. Z-score 정규화는 최솟값-최댓값(Min-Max) 스케일링 기법에 비해 경사하강법 적용에 어려움이 있다.\n",
    "\n",
    "> 답 : 1"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}